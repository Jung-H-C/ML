{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "부스팅 모델 중 가장 유명한 XGBoost를 활용하여 커플 성사를 예측하고,\n",
    "그리드 서치로 하이퍼파라미터를 튜닝하여 더 나은 모델을 만들자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "랜덤 포레스트: 각 트리를 독립적으로 만드는 알고리즘 <br>\n",
    "부스팅: 순차적으로 트리를 만들어 이전 트리로부터 더 나은 트리를 만들어내는 알고리즘입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost는 가장 먼저 개발되기도 했고, 가장 널리 활용됩니다.<br>\n",
    "XGBoost는 손실 함수뿐만 아니라 모형 복잡도까지 고려합니다.<br>\n",
    "캐글 컴피티션 우승자가 많이 사용하는 성능이 검증된 부스팅 모델입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "장점:\n",
    "- 예측속도가 상당히 빠르며, 예측력 또한 좋습니다.\n",
    "- 변수 종류가 많고 데이터가 클수록 상대적으로 뛰어난 성능을 보입니다\n",
    "- 종속변수가 연속형, 범주형 상관없음\n",
    "- 이미지나 자연어가 아닌 표로 정리된 데이터의 경우, 거의 모든 상황에 활용 가능\n",
    "\n",
    "단점:\n",
    "- 복잡한 모델인 만큼, 해석에 어려움이 있습니다.\n",
    "- 더 나은 성능을 위한 하이퍼파라미터 튜닝이 까다롭습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "file_url = 'https://media.githubusercontent.com/media/musthave-ML10/data_source/main/dating.csv'\n",
    "data = pd.read_csv(file_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_null</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>age_o</th>\n",
       "      <th>race</th>\n",
       "      <th>race_o</th>\n",
       "      <th>importance_same_race</th>\n",
       "      <th>importance_same_religion</th>\n",
       "      <th>pref_o_attractive</th>\n",
       "      <th>pref_o_sincere</th>\n",
       "      <th>...</th>\n",
       "      <th>funny_partner</th>\n",
       "      <th>ambition_partner</th>\n",
       "      <th>shared_interests_partner</th>\n",
       "      <th>interests_correlate</th>\n",
       "      <th>expected_happy_with_sd_people</th>\n",
       "      <th>expected_num_interested_in_me</th>\n",
       "      <th>like</th>\n",
       "      <th>guess_prob_liked</th>\n",
       "      <th>met</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Asian/PacificIslander/Asian-American</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Asian/PacificIslander/Asian-American</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Asian/PacificIslander/Asian-American</td>\n",
       "      <td>Asian/PacificIslander/Asian-American</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Asian/PacificIslander/Asian-American</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Asian/PacificIslander/Asian-American</td>\n",
       "      <td>Latino/HispanicAmerican</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   has_null  gender   age  age_o                                  race  \\\n",
       "0         0  female  21.0   27.0  Asian/PacificIslander/Asian-American   \n",
       "1         0  female  21.0   22.0  Asian/PacificIslander/Asian-American   \n",
       "2         1  female  21.0   22.0  Asian/PacificIslander/Asian-American   \n",
       "3         0  female  21.0   23.0  Asian/PacificIslander/Asian-American   \n",
       "4         0  female  21.0   24.0  Asian/PacificIslander/Asian-American   \n",
       "\n",
       "                                 race_o  importance_same_race  \\\n",
       "0           European/Caucasian-American                   2.0   \n",
       "1           European/Caucasian-American                   2.0   \n",
       "2  Asian/PacificIslander/Asian-American                   2.0   \n",
       "3           European/Caucasian-American                   2.0   \n",
       "4               Latino/HispanicAmerican                   2.0   \n",
       "\n",
       "   importance_same_religion  pref_o_attractive  pref_o_sincere  ...  \\\n",
       "0                       4.0               35.0            20.0  ...   \n",
       "1                       4.0               60.0             0.0  ...   \n",
       "2                       4.0               19.0            18.0  ...   \n",
       "3                       4.0               30.0             5.0  ...   \n",
       "4                       4.0               30.0            10.0  ...   \n",
       "\n",
       "   funny_partner  ambition_partner  shared_interests_partner  \\\n",
       "0            7.0               6.0                       5.0   \n",
       "1            8.0               5.0                       6.0   \n",
       "2            8.0               5.0                       7.0   \n",
       "3            7.0               6.0                       8.0   \n",
       "4            7.0               6.0                       6.0   \n",
       "\n",
       "   interests_correlate  expected_happy_with_sd_people  \\\n",
       "0                 0.14                            3.0   \n",
       "1                 0.54                            3.0   \n",
       "2                 0.16                            3.0   \n",
       "3                 0.61                            3.0   \n",
       "4                 0.21                            3.0   \n",
       "\n",
       "   expected_num_interested_in_me  like  guess_prob_liked  met  match  \n",
       "0                            2.0   7.0               6.0  0.0      0  \n",
       "1                            2.0   7.0               5.0  1.0      0  \n",
       "2                            2.0   7.0               NaN  1.0      1  \n",
       "3                            2.0   7.0               6.0  0.0      1  \n",
       "4                            2.0   6.0               6.0  0.0      1  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8378 entries, 0 to 8377\n",
      "Data columns (total 39 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   has_null                       8378 non-null   int64  \n",
      " 1   gender                         8378 non-null   object \n",
      " 2   age                            8283 non-null   float64\n",
      " 3   age_o                          8274 non-null   float64\n",
      " 4   race                           8315 non-null   object \n",
      " 5   race_o                         8305 non-null   object \n",
      " 6   importance_same_race           8299 non-null   float64\n",
      " 7   importance_same_religion       8299 non-null   float64\n",
      " 8   pref_o_attractive              8289 non-null   float64\n",
      " 9   pref_o_sincere                 8289 non-null   float64\n",
      " 10  pref_o_intelligence            8289 non-null   float64\n",
      " 11  pref_o_funny                   8280 non-null   float64\n",
      " 12  pref_o_ambitious               8271 non-null   float64\n",
      " 13  pref_o_shared_interests        8249 non-null   float64\n",
      " 14  attractive_o                   8166 non-null   float64\n",
      " 15  sincere_o                      8091 non-null   float64\n",
      " 16  intelligence_o                 8072 non-null   float64\n",
      " 17  funny_o                        8018 non-null   float64\n",
      " 18  ambitous_o                     7656 non-null   float64\n",
      " 19  shared_interests_o             7302 non-null   float64\n",
      " 20  attractive_important           8299 non-null   float64\n",
      " 21  sincere_important              8299 non-null   float64\n",
      " 22  intellicence_important         8299 non-null   float64\n",
      " 23  funny_important                8289 non-null   float64\n",
      " 24  ambtition_important            8279 non-null   float64\n",
      " 25  shared_interests_important     8257 non-null   float64\n",
      " 26  attractive_partner             8176 non-null   float64\n",
      " 27  sincere_partner                8101 non-null   float64\n",
      " 28  intelligence_partner           8082 non-null   float64\n",
      " 29  funny_partner                  8028 non-null   float64\n",
      " 30  ambition_partner               7666 non-null   float64\n",
      " 31  shared_interests_partner       7311 non-null   float64\n",
      " 32  interests_correlate            8220 non-null   float64\n",
      " 33  expected_happy_with_sd_people  8277 non-null   float64\n",
      " 34  expected_num_interested_in_me  1800 non-null   float64\n",
      " 35  like                           8138 non-null   float64\n",
      " 36  guess_prob_liked               8069 non-null   float64\n",
      " 37  met                            8003 non-null   float64\n",
      " 38  match                          8378 non-null   int64  \n",
      "dtypes: float64(34), int64(2), object(3)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8378 entries, 0 to 8377\n",
      "Data columns (total 39 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   has_null                       8378 non-null   int64  \n",
      " 1   gender                         8378 non-null   object \n",
      " 2   age                            8283 non-null   float64\n",
      " 3   age_o                          8274 non-null   float64\n",
      " 4   race                           8315 non-null   object \n",
      " 5   race_o                         8305 non-null   object \n",
      " 6   importance_same_race           8299 non-null   float64\n",
      " 7   importance_same_religion       8299 non-null   float64\n",
      " 8   pref_o_attractive              8289 non-null   float64\n",
      " 9   pref_o_sincere                 8289 non-null   float64\n",
      " 10  pref_o_intelligence            8289 non-null   float64\n",
      " 11  pref_o_funny                   8280 non-null   float64\n",
      " 12  pref_o_ambitious               8271 non-null   float64\n",
      " 13  pref_o_shared_interests        8249 non-null   float64\n",
      " 14  attractive_o                   8166 non-null   float64\n",
      " 15  sincere_o                      8091 non-null   float64\n",
      " 16  intelligence_o                 8072 non-null   float64\n",
      " 17  funny_o                        8018 non-null   float64\n",
      " 18  ambitous_o                     7656 non-null   float64\n",
      " 19  shared_interests_o             7302 non-null   float64\n",
      " 20  attractive_important           8299 non-null   float64\n",
      " 21  sincere_important              8299 non-null   float64\n",
      " 22  intellicence_important         8299 non-null   float64\n",
      " 23  funny_important                8289 non-null   float64\n",
      " 24  ambtition_important            8279 non-null   float64\n",
      " 25  shared_interests_important     8257 non-null   float64\n",
      " 26  attractive_partner             8176 non-null   float64\n",
      " 27  sincere_partner                8101 non-null   float64\n",
      " 28  intelligence_partner           8082 non-null   float64\n",
      " 29  funny_partner                  8028 non-null   float64\n",
      " 30  ambition_partner               7666 non-null   float64\n",
      " 31  shared_interests_partner       7311 non-null   float64\n",
      " 32  interests_correlate            8220 non-null   float64\n",
      " 33  expected_happy_with_sd_people  8277 non-null   float64\n",
      " 34  expected_num_interested_in_me  1800 non-null   float64\n",
      " 35  like                           8138 non-null   float64\n",
      " 36  guess_prob_liked               8069 non-null   float64\n",
      " 37  met                            8003 non-null   float64\n",
      " 38  match                          8378 non-null   int64  \n",
      "dtypes: float64(34), int64(2), object(3)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "has null\n",
    "- 무응답 항목이 있는지에 대한 정보\n",
    "\n",
    "age/age_o\n",
    "- 본인 나이/ 상대방 나이\n",
    "\n",
    "race/ race_o\n",
    "- 본인과 상대의 인종 정보\n",
    "\n",
    "importance_same_race/ importance_same_religion\n",
    "- 본인과 같은 인종과 종교를 중요시 여기는지에 대한 응답\n",
    "\n",
    "변수 6개에 대한 4가지 관점 조사 (attractive, sincere, intelligence, funny, ambitious, shared_interests):\n",
    "- 상대방 얼마나 중요시, 상대방의 평가, 본인이 중요시, 본인의 평가\n",
    "\n",
    "외 여러가지 변수들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 총 8378개의 관측치, 39개의 변수\n",
    "# 마지막 match가 종속변수이며 나머지는 독립변수."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_null</th>\n",
       "      <th>age</th>\n",
       "      <th>age_o</th>\n",
       "      <th>importance_same_race</th>\n",
       "      <th>importance_same_religion</th>\n",
       "      <th>pref_o_attractive</th>\n",
       "      <th>pref_o_sincere</th>\n",
       "      <th>pref_o_intelligence</th>\n",
       "      <th>pref_o_funny</th>\n",
       "      <th>pref_o_ambitious</th>\n",
       "      <th>pref_o_shared_interests</th>\n",
       "      <th>attractive_o</th>\n",
       "      <th>sincere_o</th>\n",
       "      <th>intelligence_o</th>\n",
       "      <th>funny_o</th>\n",
       "      <th>ambitous_o</th>\n",
       "      <th>shared_interests_o</th>\n",
       "      <th>attractive_important</th>\n",
       "      <th>sincere_important</th>\n",
       "      <th>intellicence_important</th>\n",
       "      <th>funny_important</th>\n",
       "      <th>ambtition_important</th>\n",
       "      <th>shared_interests_important</th>\n",
       "      <th>attractive_partner</th>\n",
       "      <th>sincere_partner</th>\n",
       "      <th>intelligence_partner</th>\n",
       "      <th>funny_partner</th>\n",
       "      <th>ambition_partner</th>\n",
       "      <th>shared_interests_partner</th>\n",
       "      <th>interests_correlate</th>\n",
       "      <th>expected_happy_with_sd_people</th>\n",
       "      <th>expected_num_interested_in_me</th>\n",
       "      <th>like</th>\n",
       "      <th>guess_prob_liked</th>\n",
       "      <th>met</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8378.00</td>\n",
       "      <td>8283.00</td>\n",
       "      <td>8274.00</td>\n",
       "      <td>8299.00</td>\n",
       "      <td>8299.00</td>\n",
       "      <td>8289.00</td>\n",
       "      <td>8289.00</td>\n",
       "      <td>8289.00</td>\n",
       "      <td>8280.00</td>\n",
       "      <td>8271.00</td>\n",
       "      <td>8249.00</td>\n",
       "      <td>8166.00</td>\n",
       "      <td>8091.00</td>\n",
       "      <td>8072.00</td>\n",
       "      <td>8018.00</td>\n",
       "      <td>7656.00</td>\n",
       "      <td>7302.00</td>\n",
       "      <td>8299.00</td>\n",
       "      <td>8299.00</td>\n",
       "      <td>8299.00</td>\n",
       "      <td>8289.00</td>\n",
       "      <td>8279.00</td>\n",
       "      <td>8257.00</td>\n",
       "      <td>8176.00</td>\n",
       "      <td>8101.00</td>\n",
       "      <td>8082.00</td>\n",
       "      <td>8028.00</td>\n",
       "      <td>7666.00</td>\n",
       "      <td>7311.00</td>\n",
       "      <td>8220.00</td>\n",
       "      <td>8277.00</td>\n",
       "      <td>1800.00</td>\n",
       "      <td>8138.00</td>\n",
       "      <td>8069.00</td>\n",
       "      <td>8003.00</td>\n",
       "      <td>8378.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.87</td>\n",
       "      <td>26.36</td>\n",
       "      <td>26.36</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.65</td>\n",
       "      <td>22.50</td>\n",
       "      <td>17.40</td>\n",
       "      <td>20.27</td>\n",
       "      <td>17.46</td>\n",
       "      <td>10.69</td>\n",
       "      <td>11.85</td>\n",
       "      <td>6.19</td>\n",
       "      <td>7.18</td>\n",
       "      <td>7.37</td>\n",
       "      <td>6.40</td>\n",
       "      <td>6.78</td>\n",
       "      <td>5.47</td>\n",
       "      <td>22.51</td>\n",
       "      <td>17.40</td>\n",
       "      <td>20.27</td>\n",
       "      <td>17.46</td>\n",
       "      <td>10.68</td>\n",
       "      <td>11.85</td>\n",
       "      <td>6.19</td>\n",
       "      <td>7.18</td>\n",
       "      <td>7.37</td>\n",
       "      <td>6.40</td>\n",
       "      <td>6.78</td>\n",
       "      <td>5.47</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5.53</td>\n",
       "      <td>5.57</td>\n",
       "      <td>6.13</td>\n",
       "      <td>5.21</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.33</td>\n",
       "      <td>3.57</td>\n",
       "      <td>3.56</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.81</td>\n",
       "      <td>12.57</td>\n",
       "      <td>7.04</td>\n",
       "      <td>6.78</td>\n",
       "      <td>6.09</td>\n",
       "      <td>6.13</td>\n",
       "      <td>6.36</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.79</td>\n",
       "      <td>2.16</td>\n",
       "      <td>12.59</td>\n",
       "      <td>7.05</td>\n",
       "      <td>6.78</td>\n",
       "      <td>6.09</td>\n",
       "      <td>6.12</td>\n",
       "      <td>6.36</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.79</td>\n",
       "      <td>2.16</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.73</td>\n",
       "      <td>4.76</td>\n",
       "      <td>1.84</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>17.39</td>\n",
       "      <td>15.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>9.52</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>17.39</td>\n",
       "      <td>15.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>9.52</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>18.37</td>\n",
       "      <td>20.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.64</td>\n",
       "      <td>6.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>18.18</td>\n",
       "      <td>20.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.64</td>\n",
       "      <td>6.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>6.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.00</td>\n",
       "      <td>28.00</td>\n",
       "      <td>28.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>23.81</td>\n",
       "      <td>20.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>23.81</td>\n",
       "      <td>20.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.43</td>\n",
       "      <td>7.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00</td>\n",
       "      <td>55.00</td>\n",
       "      <td>55.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>53.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>10.50</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>53.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>10.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       has_null      age    age_o  importance_same_race  \\\n",
       "count   8378.00  8283.00  8274.00               8299.00   \n",
       "mean       0.87    26.36    26.36                  3.78   \n",
       "std        0.33     3.57     3.56                  2.85   \n",
       "min        0.00    18.00    18.00                  0.00   \n",
       "25%        1.00    24.00    24.00                  1.00   \n",
       "50%        1.00    26.00    26.00                  3.00   \n",
       "75%        1.00    28.00    28.00                  6.00   \n",
       "max        1.00    55.00    55.00                 10.00   \n",
       "\n",
       "       importance_same_religion  pref_o_attractive  pref_o_sincere  \\\n",
       "count                   8299.00            8289.00         8289.00   \n",
       "mean                       3.65              22.50           17.40   \n",
       "std                        2.81              12.57            7.04   \n",
       "min                        1.00               0.00            0.00   \n",
       "25%                        1.00              15.00           15.00   \n",
       "50%                        3.00              20.00           18.37   \n",
       "75%                        6.00              25.00           20.00   \n",
       "max                       10.00             100.00           60.00   \n",
       "\n",
       "       pref_o_intelligence  pref_o_funny  pref_o_ambitious  \\\n",
       "count              8289.00       8280.00           8271.00   \n",
       "mean                 20.27         17.46             10.69   \n",
       "std                   6.78          6.09              6.13   \n",
       "min                   0.00          0.00              0.00   \n",
       "25%                  17.39         15.00              5.00   \n",
       "50%                  20.00         18.00             10.00   \n",
       "75%                  23.81         20.00             15.00   \n",
       "max                  50.00         50.00             53.00   \n",
       "\n",
       "       pref_o_shared_interests  attractive_o  sincere_o  intelligence_o  \\\n",
       "count                  8249.00       8166.00    8091.00         8072.00   \n",
       "mean                     11.85          6.19       7.18            7.37   \n",
       "std                       6.36          1.95       1.74            1.55   \n",
       "min                       0.00          0.00       0.00            0.00   \n",
       "25%                       9.52          5.00       6.00            6.00   \n",
       "50%                      10.64          6.00       7.00            7.00   \n",
       "75%                      16.00          8.00       8.00            8.00   \n",
       "max                      30.00         10.50      10.00           10.00   \n",
       "\n",
       "       funny_o  ambitous_o  shared_interests_o  attractive_important  \\\n",
       "count  8018.00     7656.00             7302.00               8299.00   \n",
       "mean      6.40        6.78                5.47                 22.51   \n",
       "std       1.95        1.79                2.16                 12.59   \n",
       "min       0.00        0.00                0.00                  0.00   \n",
       "25%       5.00        6.00                4.00                 15.00   \n",
       "50%       7.00        7.00                6.00                 20.00   \n",
       "75%       8.00        8.00                7.00                 25.00   \n",
       "max      11.00       10.00               10.00                100.00   \n",
       "\n",
       "       sincere_important  intellicence_important  funny_important  \\\n",
       "count            8299.00                 8299.00          8289.00   \n",
       "mean               17.40                   20.27            17.46   \n",
       "std                 7.05                    6.78             6.09   \n",
       "min                 0.00                    0.00             0.00   \n",
       "25%                15.00                   17.39            15.00   \n",
       "50%                18.18                   20.00            18.00   \n",
       "75%                20.00                   23.81            20.00   \n",
       "max                60.00                   50.00            50.00   \n",
       "\n",
       "       ambtition_important  shared_interests_important  attractive_partner  \\\n",
       "count              8279.00                     8257.00             8176.00   \n",
       "mean                 10.68                       11.85                6.19   \n",
       "std                   6.12                        6.36                1.95   \n",
       "min                   0.00                        0.00                0.00   \n",
       "25%                   5.00                        9.52                5.00   \n",
       "50%                  10.00                       10.64                6.00   \n",
       "75%                  15.00                       16.00                8.00   \n",
       "max                  53.00                       30.00               10.00   \n",
       "\n",
       "       sincere_partner  intelligence_partner  funny_partner  ambition_partner  \\\n",
       "count          8101.00               8082.00        8028.00           7666.00   \n",
       "mean              7.18                  7.37           6.40              6.78   \n",
       "std               1.74                  1.55           1.95              1.79   \n",
       "min               0.00                  0.00           0.00              0.00   \n",
       "25%               6.00                  6.00           5.00              6.00   \n",
       "50%               7.00                  7.00           7.00              7.00   \n",
       "75%               8.00                  8.00           8.00              8.00   \n",
       "max              10.00                 10.00          10.00             10.00   \n",
       "\n",
       "       shared_interests_partner  interests_correlate  \\\n",
       "count                   7311.00              8220.00   \n",
       "mean                       5.47                 0.20   \n",
       "std                        2.16                 0.30   \n",
       "min                        0.00                -0.83   \n",
       "25%                        4.00                -0.02   \n",
       "50%                        6.00                 0.21   \n",
       "75%                        7.00                 0.43   \n",
       "max                       10.00                 0.91   \n",
       "\n",
       "       expected_happy_with_sd_people  expected_num_interested_in_me     like  \\\n",
       "count                        8277.00                        1800.00  8138.00   \n",
       "mean                            5.53                           5.57     6.13   \n",
       "std                             1.73                           4.76     1.84   \n",
       "min                             1.00                           0.00     0.00   \n",
       "25%                             5.00                           2.00     5.00   \n",
       "50%                             6.00                           4.00     6.00   \n",
       "75%                             7.00                           8.00     7.00   \n",
       "max                            10.00                          20.00    10.00   \n",
       "\n",
       "       guess_prob_liked      met    match  \n",
       "count           8069.00  8003.00  8378.00  \n",
       "mean               5.21     0.05     0.16  \n",
       "std                2.13     0.28     0.37  \n",
       "min                0.00     0.00     0.00  \n",
       "25%                4.00     0.00     0.00  \n",
       "50%                5.00     0.00     0.00  \n",
       "75%                7.00     0.00     0.00  \n",
       "max               10.00     8.00     1.00  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(data.describe(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "has_null                         0.000000\n",
       "gender                           0.000000\n",
       "age                              0.011339\n",
       "age_o                            0.012413\n",
       "race                             0.007520\n",
       "race_o                           0.008713\n",
       "importance_same_race             0.009429\n",
       "importance_same_religion         0.009429\n",
       "pref_o_attractive                0.010623\n",
       "pref_o_sincere                   0.010623\n",
       "pref_o_intelligence              0.010623\n",
       "pref_o_funny                     0.011697\n",
       "pref_o_ambitious                 0.012772\n",
       "pref_o_shared_interests          0.015397\n",
       "attractive_o                     0.025304\n",
       "sincere_o                        0.034256\n",
       "intelligence_o                   0.036524\n",
       "funny_o                          0.042970\n",
       "ambitous_o                       0.086178\n",
       "shared_interests_o               0.128432\n",
       "attractive_important             0.009429\n",
       "sincere_important                0.009429\n",
       "intellicence_important           0.009429\n",
       "funny_important                  0.010623\n",
       "ambtition_important              0.011817\n",
       "shared_interests_important       0.014443\n",
       "attractive_partner               0.024111\n",
       "sincere_partner                  0.033063\n",
       "intelligence_partner             0.035331\n",
       "funny_partner                    0.041776\n",
       "ambition_partner                 0.084984\n",
       "shared_interests_partner         0.127357\n",
       "interests_correlate              0.018859\n",
       "expected_happy_with_sd_people    0.012055\n",
       "expected_num_interested_in_me    0.785152\n",
       "like                             0.028646\n",
       "guess_prob_liked                 0.036882\n",
       "met                              0.044760\n",
       "match                            0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree형태의 algorithm은 결측치를 주로 -99로 처리하는데, 만약 결측치라는 사실 자체가 유의미한 차이를 보인다면\n",
    "# -99를 분류하는 노드가 생겨날 겁니다.\n",
    "\n",
    "# 우선 중요도와 관련된 변수들은 결측치를 제거합니다! (-99가 outlier가 될 수 있기 때문)\n",
    "\n",
    "data = data.dropna(subset=['pref_o_attractive', 'pref_o_sincere', 'pref_o_intelligence', 'pref_o_funny', 'pref_o_ambitious', 'pref_o_shared_interests','attractive_important', 'sincere_important', 'intellicence_important', 'funny_important', 'ambtition_important', 'shared_interests_important'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "has_null                         0.000000\n",
       "gender                           0.000000\n",
       "age                              0.002706\n",
       "age_o                            0.002706\n",
       "race                             0.000000\n",
       "race_o                           0.000000\n",
       "importance_same_race             0.000000\n",
       "importance_same_religion         0.000000\n",
       "pref_o_attractive                0.000000\n",
       "pref_o_sincere                   0.000000\n",
       "pref_o_intelligence              0.000000\n",
       "pref_o_funny                     0.000000\n",
       "pref_o_ambitious                 0.000000\n",
       "pref_o_shared_interests          0.000000\n",
       "attractive_o                     0.022755\n",
       "sincere_o                        0.031488\n",
       "intelligence_o                   0.034071\n",
       "funny_o                          0.040590\n",
       "ambitous_o                       0.084625\n",
       "shared_interests_o               0.127798\n",
       "attractive_important             0.000000\n",
       "sincere_important                0.000000\n",
       "intellicence_important           0.000000\n",
       "funny_important                  0.000000\n",
       "ambtition_important              0.000000\n",
       "shared_interests_important       0.000000\n",
       "attractive_partner               0.022755\n",
       "sincere_partner                  0.031488\n",
       "intelligence_partner             0.034071\n",
       "funny_partner                    0.040590\n",
       "ambition_partner                 0.084625\n",
       "shared_interests_partner         0.127798\n",
       "interests_correlate              0.000000\n",
       "expected_happy_with_sd_people    0.002706\n",
       "expected_num_interested_in_me    0.788438\n",
       "like                             0.027306\n",
       "guess_prob_liked                 0.035301\n",
       "met                              0.043419\n",
       "match                            0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나머지 변수들의 결측치는 -99로 채웁시다\n",
    "data = data.fillna(-99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_gap(x):\n",
    "    if x['age'] == -99:\n",
    "        return -99\n",
    "    elif x['age_o'] == -99:\n",
    "        return -99\n",
    "    elif x['gender'] == 'female':\n",
    "        return x['age_o'] - x['age']\n",
    "    else:\n",
    "        return x['age'] - x['age_o']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 남자가 연상이면 +값이, 여자가 연상이면 - 값\n",
    "data['age_gap'] = data.apply(age_gap, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['age_gap_abs'] = abs(data['age_gap'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_race(x):\n",
    "    if x['race'] == -99:\n",
    "        return -99\n",
    "    elif x['race_o'] == -99:\n",
    "        return -99\n",
    "    elif x['race'] == x['race_o']:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['same_race'] = data.apply(same_race, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_race_point(x):\n",
    "    if x['same_race'] == -99:\n",
    "        return -99\n",
    "    else:\n",
    "        return x['same_race'] * x['importance_same_race']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['same_race_point'] = data.apply(same_race_point, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_null</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>age_o</th>\n",
       "      <th>race</th>\n",
       "      <th>race_o</th>\n",
       "      <th>importance_same_race</th>\n",
       "      <th>importance_same_religion</th>\n",
       "      <th>pref_o_attractive</th>\n",
       "      <th>pref_o_sincere</th>\n",
       "      <th>pref_o_intelligence</th>\n",
       "      <th>pref_o_funny</th>\n",
       "      <th>pref_o_ambitious</th>\n",
       "      <th>pref_o_shared_interests</th>\n",
       "      <th>attractive_o</th>\n",
       "      <th>sincere_o</th>\n",
       "      <th>intelligence_o</th>\n",
       "      <th>funny_o</th>\n",
       "      <th>ambitous_o</th>\n",
       "      <th>shared_interests_o</th>\n",
       "      <th>...</th>\n",
       "      <th>funny_important</th>\n",
       "      <th>ambtition_important</th>\n",
       "      <th>shared_interests_important</th>\n",
       "      <th>attractive_partner</th>\n",
       "      <th>sincere_partner</th>\n",
       "      <th>intelligence_partner</th>\n",
       "      <th>funny_partner</th>\n",
       "      <th>ambition_partner</th>\n",
       "      <th>shared_interests_partner</th>\n",
       "      <th>interests_correlate</th>\n",
       "      <th>expected_happy_with_sd_people</th>\n",
       "      <th>expected_num_interested_in_me</th>\n",
       "      <th>like</th>\n",
       "      <th>guess_prob_liked</th>\n",
       "      <th>met</th>\n",
       "      <th>match</th>\n",
       "      <th>age_gap</th>\n",
       "      <th>age_gap_abs</th>\n",
       "      <th>same_race</th>\n",
       "      <th>same_race_point</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Asian/PacificIslander/Asian-American</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Asian/PacificIslander/Asian-American</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Asian/PacificIslander/Asian-American</td>\n",
       "      <td>Asian/PacificIslander/Asian-American</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Asian/PacificIslander/Asian-American</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Asian/PacificIslander/Asian-American</td>\n",
       "      <td>Latino/HispanicAmerican</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   has_null  gender   age  age_o                                  race  \\\n",
       "0         0  female  21.0   27.0  Asian/PacificIslander/Asian-American   \n",
       "1         0  female  21.0   22.0  Asian/PacificIslander/Asian-American   \n",
       "2         1  female  21.0   22.0  Asian/PacificIslander/Asian-American   \n",
       "3         0  female  21.0   23.0  Asian/PacificIslander/Asian-American   \n",
       "4         0  female  21.0   24.0  Asian/PacificIslander/Asian-American   \n",
       "\n",
       "                                 race_o  importance_same_race  \\\n",
       "0           European/Caucasian-American                   2.0   \n",
       "1           European/Caucasian-American                   2.0   \n",
       "2  Asian/PacificIslander/Asian-American                   2.0   \n",
       "3           European/Caucasian-American                   2.0   \n",
       "4               Latino/HispanicAmerican                   2.0   \n",
       "\n",
       "   importance_same_religion  pref_o_attractive  pref_o_sincere  \\\n",
       "0                       4.0               35.0            20.0   \n",
       "1                       4.0               60.0             0.0   \n",
       "2                       4.0               19.0            18.0   \n",
       "3                       4.0               30.0             5.0   \n",
       "4                       4.0               30.0            10.0   \n",
       "\n",
       "   pref_o_intelligence  pref_o_funny  pref_o_ambitious  \\\n",
       "0                 20.0          20.0               0.0   \n",
       "1                  0.0          40.0               0.0   \n",
       "2                 19.0          18.0              14.0   \n",
       "3                 15.0          40.0               5.0   \n",
       "4                 20.0          10.0              10.0   \n",
       "\n",
       "   pref_o_shared_interests  attractive_o  sincere_o  intelligence_o  funny_o  \\\n",
       "0                      5.0           6.0        8.0             8.0      8.0   \n",
       "1                      0.0           7.0        8.0            10.0      7.0   \n",
       "2                     12.0          10.0       10.0            10.0     10.0   \n",
       "3                      5.0           7.0        8.0             9.0      8.0   \n",
       "4                     20.0           8.0        7.0             9.0      6.0   \n",
       "\n",
       "   ambitous_o  shared_interests_o  ...  funny_important  ambtition_important  \\\n",
       "0         8.0                 6.0  ...             15.0                 15.0   \n",
       "1         7.0                 5.0  ...             15.0                 15.0   \n",
       "2        10.0                10.0  ...             15.0                 15.0   \n",
       "3         9.0                 8.0  ...             15.0                 15.0   \n",
       "4         9.0                 7.0  ...             15.0                 15.0   \n",
       "\n",
       "   shared_interests_important  attractive_partner  sincere_partner  \\\n",
       "0                        15.0                 6.0              9.0   \n",
       "1                        15.0                 7.0              8.0   \n",
       "2                        15.0                 5.0              8.0   \n",
       "3                        15.0                 7.0              6.0   \n",
       "4                        15.0                 5.0              6.0   \n",
       "\n",
       "   intelligence_partner  funny_partner  ambition_partner  \\\n",
       "0                   7.0            7.0               6.0   \n",
       "1                   7.0            8.0               5.0   \n",
       "2                   9.0            8.0               5.0   \n",
       "3                   8.0            7.0               6.0   \n",
       "4                   7.0            7.0               6.0   \n",
       "\n",
       "   shared_interests_partner  interests_correlate  \\\n",
       "0                       5.0                 0.14   \n",
       "1                       6.0                 0.54   \n",
       "2                       7.0                 0.16   \n",
       "3                       8.0                 0.61   \n",
       "4                       6.0                 0.21   \n",
       "\n",
       "   expected_happy_with_sd_people  expected_num_interested_in_me  like  \\\n",
       "0                            3.0                            2.0   7.0   \n",
       "1                            3.0                            2.0   7.0   \n",
       "2                            3.0                            2.0   7.0   \n",
       "3                            3.0                            2.0   7.0   \n",
       "4                            3.0                            2.0   6.0   \n",
       "\n",
       "   guess_prob_liked  met  match  age_gap  age_gap_abs  same_race  \\\n",
       "0               6.0  0.0      0      6.0          6.0         -1   \n",
       "1               5.0  1.0      0      1.0          1.0         -1   \n",
       "2             -99.0  1.0      1      1.0          1.0          1   \n",
       "3               6.0  0.0      1      2.0          2.0         -1   \n",
       "4               6.0  0.0      1      3.0          3.0         -1   \n",
       "\n",
       "   same_race_point  \n",
       "0             -2.0  \n",
       "1             -2.0  \n",
       "2              2.0  \n",
       "3             -2.0  \n",
       "4             -2.0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating(data, importance, score):\n",
    "    if data[importance] == -99:\n",
    "        return -99\n",
    "    elif data[score] == -99:\n",
    "        return -99\n",
    "    else:\n",
    "        return data[importance] * data[score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pref_o_attractive', 'pref_o_sincere', 'pref_o_intelligence',\n",
       "       'pref_o_funny', 'pref_o_ambitious', 'pref_o_shared_interests'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns[8:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "partner_imp = data.columns[8:14]\n",
    "partner_rate_me = data.columns[14:20]\n",
    "my_imp = data.columns[20:26]\n",
    "my_rate_partner = data.columns[26:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_label_partner = ['attractive_p', 'sincere_partner_p', 'intelligence_p', 'funny_p', 'ambition_p', 'shared_interests_p']\n",
    "\n",
    "new_label_me = ['attractive_m', 'sincere_partner_m', 'intelligence_m', 'funny_m', 'ambition_m', 'shared_interests_m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j, k in zip(new_label_partner, partner_imp, partner_rate_me):\n",
    "    data[i] = data.apply(lambda x: rating(x, j, k), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j, k in zip(new_label_me, my_imp, my_rate_partner):\n",
    "    data[i] = data.apply(lambda x: rating(x, j, k), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data, columns=['gender', 'race', 'race_o'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop('match', axis=1), data['match'], test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(n_estimators = 500, max_depth = 5, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=100, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=100, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=100, ...)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8690036900369004"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1300   65]\n",
      " [ 148  113]]\n"
     ]
    }
   ],
   "source": [
    "# 해당 accuracy가 좋은 값은 아님. 애초에 매칭률이 16%정도이므로 모두 0으로 예측해도 84%는 맞출수 있기 때문\n",
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92      1365\n",
      "           1       0.63      0.43      0.51       261\n",
      "\n",
      "    accuracy                           0.87      1626\n",
      "   macro avg       0.77      0.69      0.72      1626\n",
      "weighted avg       0.86      0.87      0.86      1626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 실제 안됐는데 됐다고 한 경우가 65건,\n",
    "# 실제 됐는데 안됐다고 한 경우가 148건\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 목표값중 1(매칭 성사된 경우)에 대해서 정확도가 현저하게 떨어진다.\n",
    "\n",
    "# 이번엔 하이퍼파라미터 값에 임의로 넣어서 찾지 않고,\n",
    "# Grid Search를 사용하여 수백가지의 하이퍼파라미터 값을 컴퓨터가 직접 넣게 한다.\n",
    "\n",
    "# 하이퍼 파라미터 값 후보 정의\n",
    "max_depth = [3, 5, 10]\n",
    "learning_rate = [0.01, 0.05, 0.1]\n",
    "\n",
    "# 9가지 조합 완성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "    'learning_rate' : [0.01, 0.1, 0.3],\n",
    "    'max_depth' : [5, 7, 10], \n",
    "    # subsample: 데이터의 percentage만 사용하여 tree제작 (overfitting 방지 가능)\n",
    "    'subsample' : [0.5, 0.7, 1],\n",
    "    # n_estimators: 전체 나무의 개수\n",
    "    'n_estimators' : [300, 500, 1000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search 이용하여 다시 모델링 ㄱㄱ\n",
    "model = xgb.XGBClassifier()\n",
    "gs_model = GridSearchCV(model, parameters, n_jobs=-1, scoring='f1', cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 0.3],\n",
       "                         &#x27;max_depth&#x27;: [5, 7, 10],\n",
       "                         &#x27;n_estimators&#x27;: [300, 500, 1000],\n",
       "                         &#x27;subsample&#x27;: [0.5, 0.7, 1]},\n",
       "             scoring=&#x27;f1&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 0.3],\n",
       "                         &#x27;max_depth&#x27;: [5, 7, 10],\n",
       "                         &#x27;n_estimators&#x27;: [300, 500, 1000],\n",
       "                         &#x27;subsample&#x27;: [0.5, 0.7, 1]},\n",
       "             scoring=&#x27;f1&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.1, 0.3],\n",
       "                         'max_depth': [5, 7, 10],\n",
       "                         'n_estimators': [300, 500, 1000],\n",
       "                         'subsample': [0.5, 0.7, 1]},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델링을 거친후, 적용되는 모델은 최적의 하이퍼파라미터 조합이 자동 반영됨\n",
    "pred = gs_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8677736777367774"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search를 통한 hyper parameter tuning 후에도 accuracy가 많이 개선되지는 못했음\n",
    "# 결국 accuracy를 크게 올리려면, feature engineering과 model algorithm 선정이 영향을 미친다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.3, 'max_depth': 5, 'n_estimators': 1000, 'subsample': 1}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최적의 하이퍼파라미터 출력\n",
    "gs_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.3, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=100, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.3, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=100, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.3, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=100, ...)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(learning_rate=0.3, max_depth=5, n_estimators=1000, subsample=0.5, random_state=100)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01819486, 0.00989549, 0.0111782 , 0.009017  , 0.01364212,\n",
       "       0.01370795, 0.01044157, 0.01432143, 0.0112383 , 0.01220805,\n",
       "       0.01187364, 0.04149368, 0.01171842, 0.00962038, 0.02816415,\n",
       "       0.01224416, 0.01914566, 0.01568731, 0.01054792, 0.01655982,\n",
       "       0.0108076 , 0.00942059, 0.01252668, 0.02517975, 0.01113309,\n",
       "       0.01056412, 0.02203647, 0.01264612, 0.01548078, 0.010767  ,\n",
       "       0.01181634, 0.02150448, 0.06137006, 0.01966265, 0.03530204,\n",
       "       0.01184297, 0.01341042, 0.00764294, 0.01332174, 0.01243445,\n",
       "       0.0120828 , 0.01323388, 0.01257525, 0.00987298, 0.00975263,\n",
       "       0.01079004, 0.01116284, 0.01194337, 0.01218576, 0.01062766,\n",
       "       0.01012287, 0.00793751, 0.04609776, 0.00929323, 0.0282979 ,\n",
       "       0.0291527 , 0.04466046, 0.01399204, 0.01555375, 0.03089423],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.DataFrame({'features': X_train.columns, 'values': model.feature_importances_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>has_null</td>\n",
       "      <td>0.018195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>age</td>\n",
       "      <td>0.009895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>age_o</td>\n",
       "      <td>0.011178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>importance_same_race</td>\n",
       "      <td>0.009017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>importance_same_religion</td>\n",
       "      <td>0.013642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pref_o_attractive</td>\n",
       "      <td>0.013708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pref_o_sincere</td>\n",
       "      <td>0.010442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pref_o_intelligence</td>\n",
       "      <td>0.014321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pref_o_funny</td>\n",
       "      <td>0.011238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pref_o_ambitious</td>\n",
       "      <td>0.012208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pref_o_shared_interests</td>\n",
       "      <td>0.011874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>attractive_o</td>\n",
       "      <td>0.041494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sincere_o</td>\n",
       "      <td>0.011718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>intelligence_o</td>\n",
       "      <td>0.009620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>funny_o</td>\n",
       "      <td>0.028164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ambitous_o</td>\n",
       "      <td>0.012244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>shared_interests_o</td>\n",
       "      <td>0.019146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>attractive_important</td>\n",
       "      <td>0.015687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sincere_important</td>\n",
       "      <td>0.010548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>intellicence_important</td>\n",
       "      <td>0.016560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>funny_important</td>\n",
       "      <td>0.010808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ambtition_important</td>\n",
       "      <td>0.009421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>shared_interests_important</td>\n",
       "      <td>0.012527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>attractive_partner</td>\n",
       "      <td>0.025180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sincere_partner</td>\n",
       "      <td>0.011133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>intelligence_partner</td>\n",
       "      <td>0.010564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>funny_partner</td>\n",
       "      <td>0.022036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ambition_partner</td>\n",
       "      <td>0.012646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>shared_interests_partner</td>\n",
       "      <td>0.015481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>interests_correlate</td>\n",
       "      <td>0.010767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>expected_happy_with_sd_people</td>\n",
       "      <td>0.011816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>expected_num_interested_in_me</td>\n",
       "      <td>0.021504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>like</td>\n",
       "      <td>0.061370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>guess_prob_liked</td>\n",
       "      <td>0.019663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>met</td>\n",
       "      <td>0.035302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>age_gap</td>\n",
       "      <td>0.011843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>age_gap_abs</td>\n",
       "      <td>0.013410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>same_race</td>\n",
       "      <td>0.007643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>same_race_point</td>\n",
       "      <td>0.013322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>attractive_p</td>\n",
       "      <td>0.012434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>sincere_partner_p</td>\n",
       "      <td>0.012083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>intelligence_p</td>\n",
       "      <td>0.013234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>funny_p</td>\n",
       "      <td>0.012575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>ambition_p</td>\n",
       "      <td>0.009873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>shared_interests_p</td>\n",
       "      <td>0.009753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>attractive_m</td>\n",
       "      <td>0.010790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>sincere_partner_m</td>\n",
       "      <td>0.011163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>intelligence_m</td>\n",
       "      <td>0.011943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>funny_m</td>\n",
       "      <td>0.012186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ambition_m</td>\n",
       "      <td>0.010628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>shared_interests_m</td>\n",
       "      <td>0.010123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>gender_male</td>\n",
       "      <td>0.007938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>race_Black/AfricanAmerican</td>\n",
       "      <td>0.046098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>race_European/Caucasian-American</td>\n",
       "      <td>0.009293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>race_Latino/HispanicAmerican</td>\n",
       "      <td>0.028298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>race_Other</td>\n",
       "      <td>0.029153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>race_o_Black/AfricanAmerican</td>\n",
       "      <td>0.044660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>race_o_European/Caucasian-American</td>\n",
       "      <td>0.013992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>race_o_Latino/HispanicAmerican</td>\n",
       "      <td>0.015554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>race_o_Other</td>\n",
       "      <td>0.030894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              features    values\n",
       "0                             has_null  0.018195\n",
       "1                                  age  0.009895\n",
       "2                                age_o  0.011178\n",
       "3                 importance_same_race  0.009017\n",
       "4             importance_same_religion  0.013642\n",
       "5                    pref_o_attractive  0.013708\n",
       "6                       pref_o_sincere  0.010442\n",
       "7                  pref_o_intelligence  0.014321\n",
       "8                         pref_o_funny  0.011238\n",
       "9                     pref_o_ambitious  0.012208\n",
       "10             pref_o_shared_interests  0.011874\n",
       "11                        attractive_o  0.041494\n",
       "12                           sincere_o  0.011718\n",
       "13                      intelligence_o  0.009620\n",
       "14                             funny_o  0.028164\n",
       "15                          ambitous_o  0.012244\n",
       "16                  shared_interests_o  0.019146\n",
       "17                attractive_important  0.015687\n",
       "18                   sincere_important  0.010548\n",
       "19              intellicence_important  0.016560\n",
       "20                     funny_important  0.010808\n",
       "21                 ambtition_important  0.009421\n",
       "22          shared_interests_important  0.012527\n",
       "23                  attractive_partner  0.025180\n",
       "24                     sincere_partner  0.011133\n",
       "25                intelligence_partner  0.010564\n",
       "26                       funny_partner  0.022036\n",
       "27                    ambition_partner  0.012646\n",
       "28            shared_interests_partner  0.015481\n",
       "29                 interests_correlate  0.010767\n",
       "30       expected_happy_with_sd_people  0.011816\n",
       "31       expected_num_interested_in_me  0.021504\n",
       "32                                like  0.061370\n",
       "33                    guess_prob_liked  0.019663\n",
       "34                                 met  0.035302\n",
       "35                             age_gap  0.011843\n",
       "36                         age_gap_abs  0.013410\n",
       "37                           same_race  0.007643\n",
       "38                     same_race_point  0.013322\n",
       "39                        attractive_p  0.012434\n",
       "40                   sincere_partner_p  0.012083\n",
       "41                      intelligence_p  0.013234\n",
       "42                             funny_p  0.012575\n",
       "43                          ambition_p  0.009873\n",
       "44                  shared_interests_p  0.009753\n",
       "45                        attractive_m  0.010790\n",
       "46                   sincere_partner_m  0.011163\n",
       "47                      intelligence_m  0.011943\n",
       "48                             funny_m  0.012186\n",
       "49                          ambition_m  0.010628\n",
       "50                  shared_interests_m  0.010123\n",
       "51                         gender_male  0.007938\n",
       "52          race_Black/AfricanAmerican  0.046098\n",
       "53    race_European/Caucasian-American  0.009293\n",
       "54        race_Latino/HispanicAmerican  0.028298\n",
       "55                          race_Other  0.029153\n",
       "56        race_o_Black/AfricanAmerican  0.044660\n",
       "57  race_o_European/Caucasian-American  0.013992\n",
       "58      race_o_Latino/HispanicAmerican  0.015554\n",
       "59                        race_o_Other  0.030894"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='values', ylabel='features'>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "sns.barplot(x='values', y='features', data=feature_imp.sort_values(by='values', ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost는 Random Forest와 달리 이전 tree를 기반으로 다음 tree를 만들어냅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KernelForNLP",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
